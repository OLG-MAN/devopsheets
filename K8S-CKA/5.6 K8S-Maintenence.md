### OS Upgrade
# commands
kubectl drain node-1            # drain node and move all wl to other nodes
kubectl drain node-1 --ignore-daemonsets
kubectl drain node-1 --ignore-daemonsets --force
kubectl uncordon node-1         # make node schedulable after drain
kubectl cordon node-2           # just make node unschedulable

### k8s versions
# commands
kubectl get nodes 
kubectl version
kubectl version --short

### Cluster Upgrade
# Need to update for +1 minor version at one time
# 3 strategies that are available to upgrade the worker nodes
# 1. upgrade all at once. But then your pods will be down and users will not be able to access the applications.
# 2. upgrade one node at a time.
# 3. add new nodes to the cluster

# Updgrade Master node kubeadm flow
kubectl drain <controlplane> (--ignore-daemonsets --force)
apt update
apt install kubeadm=<version>       # version e.g. 1.20.0-00
kubeadm upgrade plan                # Show current and latest version etc.
kubeadm upgrade apply v<version>    # version e.g. 1.20.0
apt install kubelet=<version>       # version e.g. 1.20.0-00
apt install kubectl=<version>       # version e.g. 1.20.0-00
systemctl restart kubelet
kubectl uncordon <controlplane>
kubectl get nodes

# Upgrade worker node kubeadm flow
kubectl drain <node01> (--ignore-daemonsets --force)
ssh <node01>
apt update
apt install kubeadm=<version>     # version e.g. 1.20.0-00
kubeadm upgrade plan              # Show current and latest version etc.
kubeadm upgrade node              # make kubeadm upgrade on node
apt install kubectl=<version>     # version e.g. 1.20.0-00
ap install kubelet=<version>      # version e.g. 1.20.0-00
systemctl restart kubelet
exit
kubectl uncordon <node01>

### Backup and Restore
# Simple command to save some resources (not all) in cluster
kubectl get all --all-namespaces -o yaml > all-deploy-services.yaml
# Check ETCD info values
kubectl -n kube-system describe pod <etcd-controlplane> 
kubectl -n kube-system describe pod <etcd-controlplane>  | grep '\--listen-client-urls'
kubectl -n kube-system describe pod <etcd-controlplane>  | grep '\--trusted-ca-file'
# Backup/Restore the ETCD cluster itself.
# Save a snapshot of the etcd database. Example.
ETCDCTL_API=3 etcdctl snapshot save /opt/etcd-backup.db \
--cacert=/etc/kubernetes/pki/etcd/ca.crt \
--cert=/etc/kubernetes/pki/etcd/server.crt \
--key=/etc/kubernetes/pki/etcd/server.key
# Check Status of ETCD db snapshot
ETCDCTL_API=3 etcdctl snapshot status /opt/etcd-backup.db
ETCDCTL_API=3 etcdctl --write-out=table snapshot status /opt/etcd-backup.db
# Check ETCD member list
ETCDCTL_API=3 etcdctl member list --endpoints=https://127.0.0.1:2379 \
--cacert=/etc/kubernetes/pki/etcd/ca.crt \
--cert=/etc/kubernetes/pki/etcd/server.crt \
--key=/etc/kubernetes/pki/etcd/server.key
# Restore ETCD (long flow - with options, if snapshot in other nodes)
ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
--name=master \
--cacert=/etc/kubernetes/pki/etcd/ca.crt \
--cert=/etc/kubernetes/pki/etcd/server.crt \
--key=/etc/kubernetes/pki/etcd/server.key \
--data-dir /var/lib/etcd-from-backup \
--initial-cluster=master=https://127.0.0.1:2380 \
--initial-cluster-token etcd-cluster-1 \
--initial-advertise-peer-urls=https://127.0.0.1:2380 \
snapshot restore /opt/snapshot-pre-boot.db
# Restore ETCD (fast flow - without options, if snapshot in same node)
ETCDCTL_API=3 etcdctl --data-dir /var/lib/etcd-from-backup snapshot restore /opt/snapshot-pre-boot.db
# Edit ETCD static pod manifest
vi /etc/kubernetes/manifests/etcd.yaml
# Update --data-dir to use new target location
--data-dir=/var/lib/etcd-from-backup               # (long flow)

# Update new initial-cluster-token to specify new cluster
--initial-cluster-token=etcd-cluster-1             # (long flow)

# Update volumes and volume mounts to point to new path
        volumeMounts:
          - mountPath: /var/lib/etcd-from-backup   # (long flow)
            name: etcd-data
          ...
   
   volumes:
   - hostPath:
       path: /var/lib/etcd-from-backup             # (fast flow)
       type: DirectoryOrCreate
     name: etcd-data
# Check changes commands
docker ps -a | grep etcd
watch "docker ps -a | grep etcd"
kubectl get all
# links
# https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster
# https://github.com/etcd-io/website/blob/main/content/en/docs/v3.5/op-guide/recovery.md